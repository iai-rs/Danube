{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8001b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random \n",
    "np.random.seed(42)\n",
    "data = pd.read_csv(r\"C:\\Users\\ivana\\Downloads\\Ksenobiotici_makroinvertebrate.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75dde91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>Chironomidae</td>\n",
       "      <td>...</td>\n",
       "      <td>Odonata</td>\n",
       "      <td>Odonata</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>2.4 D</td>\n",
       "      <td>Chloroxuron</td>\n",
       "      <td>Bromacil</td>\n",
       "      <td>Dimefuron</td>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>Bentazon</td>\n",
       "      <td>Fluoranthene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JDS lokalitet</td>\n",
       "      <td>Chironomus acutiventris / obtusidens Wuelker, ...</td>\n",
       "      <td>Chironomus annularis gr.</td>\n",
       "      <td>Chironomus bernensis Kloetzli, 1973</td>\n",
       "      <td>Chironomus nudiventris Ryser, Scholl &amp; Wuelker...</td>\n",
       "      <td>Chironomus cf. obtusidens Goetghebuer, 1921</td>\n",
       "      <td>Chironomus plumosus gr. Linnaeus, 1758</td>\n",
       "      <td>Cladotanytarsus conversus Johannsen, 1932</td>\n",
       "      <td>Cladotanytarsus spp.</td>\n",
       "      <td>Cricotopus bicinctus Meigen, 1818</td>\n",
       "      <td>...</td>\n",
       "      <td>Gomphus flavipes Charpentier, 1825</td>\n",
       "      <td>Gomphus vulgatissimus Linnaeus, 1758</td>\n",
       "      <td>Ceratopogonidae Gen. sp.</td>\n",
       "      <td>2.4 D</td>\n",
       "      <td>Chloroxuron</td>\n",
       "      <td>Bromacil</td>\n",
       "      <td>Dimefuron</td>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>Bentazon</td>\n",
       "      <td>Fluoranthene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JDS3 R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003404762</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.083832</td>\n",
       "      <td>0.0096127</td>\n",
       "      <td>0.0354136</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JDS3  L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003404762</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.083832</td>\n",
       "      <td>0.0096127</td>\n",
       "      <td>0.0354136</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JDS4 R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002109524</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.083832</td>\n",
       "      <td>0.0096127</td>\n",
       "      <td>0.0354136</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>JDS66 L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003961905</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0298303</td>\n",
       "      <td>0.0076381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>JDS67 R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0100676</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>JDS67 L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0100676</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>JDS68 R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001342857</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0317049</td>\n",
       "      <td>0.0080932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>JDS68 L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001342857</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0317049</td>\n",
       "      <td>0.0080932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                                  1  \\\n",
       "0              NaN                                       Chironomidae   \n",
       "1    JDS lokalitet  Chironomus acutiventris / obtusidens Wuelker, ...   \n",
       "2          JDS3 R                                                   0   \n",
       "3          JDS3  L                                                  0   \n",
       "4           JDS4 R                                                  0   \n",
       "..             ...                                                ...   \n",
       "103        JDS66 L                                                  0   \n",
       "104        JDS67 R                                                  0   \n",
       "105        JDS67 L                                                  0   \n",
       "106        JDS68 R                                                  0   \n",
       "107        JDS68 L                                                  0   \n",
       "\n",
       "                            2                                    3  \\\n",
       "0                Chironomidae                         Chironomidae   \n",
       "1    Chironomus annularis gr.  Chironomus bernensis Kloetzli, 1973   \n",
       "2                           0                                    0   \n",
       "3                           0                                    0   \n",
       "4                           0                                    0   \n",
       "..                        ...                                  ...   \n",
       "103                         0                                    0   \n",
       "104                         0                                    0   \n",
       "105                         0                                    0   \n",
       "106                         0                                    0   \n",
       "107                         0                                    0   \n",
       "\n",
       "                                                     4  \\\n",
       "0                                         Chironomidae   \n",
       "1    Chironomus nudiventris Ryser, Scholl & Wuelker...   \n",
       "2                                                    0   \n",
       "3                                                    1   \n",
       "4                                                    1   \n",
       "..                                                 ...   \n",
       "103                                                  0   \n",
       "104                                                  0   \n",
       "105                                                  0   \n",
       "106                                                  0   \n",
       "107                                                  0   \n",
       "\n",
       "                                               5  \\\n",
       "0                                   Chironomidae   \n",
       "1    Chironomus cf. obtusidens Goetghebuer, 1921   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "..                                           ...   \n",
       "103                                            0   \n",
       "104                                            0   \n",
       "105                                            0   \n",
       "106                                            0   \n",
       "107                                            0   \n",
       "\n",
       "                                          6  \\\n",
       "0                              Chironomidae   \n",
       "1    Chironomus plumosus gr. Linnaeus, 1758   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "..                                      ...   \n",
       "103                                       0   \n",
       "104                                       0   \n",
       "105                                       0   \n",
       "106                                       0   \n",
       "107                                       0   \n",
       "\n",
       "                                             7                     8  \\\n",
       "0                                 Chironomidae          Chironomidae   \n",
       "1    Cladotanytarsus conversus Johannsen, 1932  Cladotanytarsus spp.   \n",
       "2                                            0                     0   \n",
       "3                                            0                     1   \n",
       "4                                            0                     4   \n",
       "..                                         ...                   ...   \n",
       "103                                          0                     0   \n",
       "104                                          0                     0   \n",
       "105                                          0                     0   \n",
       "106                                          0                     0   \n",
       "107                                          0                     0   \n",
       "\n",
       "                                     9  ...  \\\n",
       "0                         Chironomidae  ...   \n",
       "1    Cricotopus bicinctus Meigen, 1818  ...   \n",
       "2                                    3  ...   \n",
       "3                                    2  ...   \n",
       "4                                    7  ...   \n",
       "..                                 ...  ...   \n",
       "103                                  0  ...   \n",
       "104                                  0  ...   \n",
       "105                                  0  ...   \n",
       "106                                  0  ...   \n",
       "107                                  2  ...   \n",
       "\n",
       "                                    161                                   162  \\\n",
       "0                               Odonata                               Odonata   \n",
       "1    Gomphus flavipes Charpentier, 1825  Gomphus vulgatissimus Linnaeus, 1758   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     1   \n",
       "..                                  ...                                   ...   \n",
       "103                                   0                                     0   \n",
       "104                                   0                                     0   \n",
       "105                                   0                                     0   \n",
       "106                                   0                                     0   \n",
       "107                                   1                                     0   \n",
       "\n",
       "                          163          164          165        166        167  \\\n",
       "0                     Diptera        2.4 D  Chloroxuron   Bromacil  Dimefuron   \n",
       "1    Ceratopogonidae Gen. sp.        2.4 D  Chloroxuron   Bromacil  Dimefuron   \n",
       "2                           0  0.003404762       0.0113   0.083832  0.0096127   \n",
       "3                           0  0.003404762       0.0113   0.083832  0.0096127   \n",
       "4                           0  0.002109524       0.0113   0.083832  0.0096127   \n",
       "..                        ...          ...          ...        ...        ...   \n",
       "103                         0  0.003961905       0.0057  0.0298303  0.0076381   \n",
       "104                         0            0       0.0062          0  0.0100676   \n",
       "105                         0            0       0.0062          0  0.0100676   \n",
       "106                         0  0.001342857        0.006  0.0317049  0.0080932   \n",
       "107                         0  0.001342857        0.006  0.0317049  0.0080932   \n",
       "\n",
       "             168       169           170  \n",
       "0    Amoxicillin  Bentazon  Fluoranthene  \n",
       "1    Amoxicillin  Bentazon  Fluoranthene  \n",
       "2      0.0354136     0.003        0.0047  \n",
       "3      0.0354136     0.003        0.0047  \n",
       "4      0.0354136     0.005        0.0024  \n",
       "..           ...       ...           ...  \n",
       "103            0     0.007        0.0025  \n",
       "104            0     0.007         0.002  \n",
       "105            0     0.007         0.002  \n",
       "106            0     0.008        0.0025  \n",
       "107            0     0.008        0.0025  \n",
       "\n",
       "[108 rows x 171 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1caae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.iloc[2:,[73,69,68,70,72,58,60,91]].values  \n",
    "y = data.iloc[2:,166].values \n",
    "X=X.astype(\"float32\")\n",
    "y=y.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96633466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   0.,  66.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  27.,   0.,   0.],\n",
       "       [  5.,  31.,  16.,  52.,   0.,  97.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  16.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   5.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,  53.,   0.,  35.,   0.,   0.],\n",
       "       [  0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  1.,  11.,   0.,   1.,   0.,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  85.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 372.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 142.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   7.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  74.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [ 22., 256.,  21.,  29.,   0.,   2.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  30.,   0.,  38.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  33.,   2.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 135.,   0.,   0.],\n",
       "       [  0.,  15.,   0.,  24.,  30.,  11.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 379.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  17.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   7.,   1.,   0.],\n",
       "       [  0.,   1.,   0.,   0.,   0.,  64.,  10.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  34.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 123.,   2.,   0.],\n",
       "       [ 11.,   0.,   0.,   0.,   0.,  36.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   3.,  24.,   0.,   0.],\n",
       "       [  0.,   9.,   0.,   0.,   0.,   8.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  13.,   0.,   0.],\n",
       "       [  1.,   0.,   0.,   0.,   0.,  98.,   6.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  12.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  11.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   4.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   3.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  52.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  41.,  13.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 165.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  15.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  86.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   3.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   3.,   2.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   5.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  68.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  31.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 240.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  10.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  11.,   1.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  64.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 179.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  14.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 180.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  43.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 115.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  64.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  34.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   4.,  17.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,  15.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   3.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   3.,  22.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff6a1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3698d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.083832  0.083832  0.083832  0.083832  0.0302266 0.0302266 0.0826422\n",
      " 0.0826422 0.084234  0.084234  0.0569165 0.0569165 0.0649531 0.0649531\n",
      " 0.        0.        0.        0.        0.        0.        0.0437019\n",
      " 0.0437019 0.        0.        0.0302276 0.0302276 0.186626  0.186626\n",
      " 0.0773327 0.0773327 0.0294399 0.0294399 0.0681038 0.0681038 0.0439631\n",
      " 0.0439631 0.0483794 0.0483794 0.        0.        0.        0.\n",
      " 0.        0.        0.0669014 0.0669014 0.        0.        0.0392966\n",
      " 0.0392966 0.        0.        0.        0.        0.0773376 0.0773376\n",
      " 0.1062102 0.1062102 0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.0236898 0.0236898 0.        0.        0.        0.        0.0335525\n",
      " 0.0335525 0.        0.        0.0231236 0.0231236 0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.0298303 0.0298303 0.        0.        0.0317049\n",
      " 0.0317049]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c6aea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49131d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe4edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have a numpy array or a pandas DataFrame named 'data' that you want to scale\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the data using the scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce980acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_index=np.arange(0, X.shape[0])#train index svi indeksi\n",
    "#test_index= np.random.randint(0, X.shape[0],10)#nasumice uzima 10 za test\n",
    "#train_index=np.setdiff1d(train_index, test_index)#novi train indeks bez testa\n",
    "#X_train=X[train_index,:]#sve vrednosti iz train seta\n",
    "#X_test=X[test_index,:]\n",
    "#y_train=y[train_index]\n",
    "#y_test=y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dcfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1b29a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a4a346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "76/76 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0017\n",
      "Epoch 2/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 3/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 4/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 5/200\n",
      "76/76 [==============================] - 0s 870us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 6/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/200\n",
      "76/76 [==============================] - 0s 879us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 10/200\n",
      "76/76 [==============================] - 0s 899us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 11/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 12/200\n",
      "76/76 [==============================] - 0s 865us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 13/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 14/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 15/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 16/200\n",
      "76/76 [==============================] - 0s 855us/step - loss: 0.0017 - val_loss: 9.9727e-04\n",
      "Epoch 17/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0017 - val_loss: 9.9187e-04\n",
      "Epoch 18/200\n",
      "76/76 [==============================] - 0s 849us/step - loss: 0.0017 - val_loss: 9.8727e-04\n",
      "Epoch 19/200\n",
      "76/76 [==============================] - 0s 846us/step - loss: 0.0017 - val_loss: 9.8337e-04\n",
      "Epoch 20/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0017 - val_loss: 9.8009e-04\n",
      "Epoch 21/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0017 - val_loss: 9.7736e-04\n",
      "Epoch 22/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0018 - val_loss: 9.7516e-04\n",
      "Epoch 23/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0018 - val_loss: 9.7344e-04\n",
      "Epoch 24/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0018 - val_loss: 9.7219e-04\n",
      "Epoch 25/200\n",
      "76/76 [==============================] - 0s 882us/step - loss: 0.0018 - val_loss: 9.7138e-04\n",
      "Epoch 26/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0018 - val_loss: 9.7098e-04\n",
      "Epoch 27/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0018 - val_loss: 9.7096e-04\n",
      "Epoch 28/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0018 - val_loss: 9.7129e-04\n",
      "Epoch 29/200\n",
      "76/76 [==============================] - 0s 876us/step - loss: 0.0018 - val_loss: 9.7193e-04\n",
      "Epoch 30/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0018 - val_loss: 9.7284e-04\n",
      "Epoch 31/200\n",
      "76/76 [==============================] - 0s 875us/step - loss: 0.0018 - val_loss: 9.7400e-04\n",
      "Epoch 32/200\n",
      "76/76 [==============================] - 0s 871us/step - loss: 0.0018 - val_loss: 9.7535e-04\n",
      "Epoch 33/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0018 - val_loss: 9.7685e-04\n",
      "Epoch 34/200\n",
      "76/76 [==============================] - 0s 875us/step - loss: 0.0018 - val_loss: 9.7849e-04\n",
      "Epoch 35/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0018 - val_loss: 9.8021e-04\n",
      "Epoch 36/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0018 - val_loss: 9.8199e-04\n",
      "Epoch 37/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0018 - val_loss: 9.8380e-04\n",
      "Epoch 38/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0018 - val_loss: 9.8563e-04\n",
      "Epoch 39/200\n",
      "76/76 [==============================] - 0s 883us/step - loss: 0.0018 - val_loss: 9.8745e-04\n",
      "Epoch 40/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0018 - val_loss: 9.8925e-04\n",
      "Epoch 41/200\n",
      "76/76 [==============================] - 0s 871us/step - loss: 0.0018 - val_loss: 9.9102e-04\n",
      "Epoch 42/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0018 - val_loss: 9.9275e-04\n",
      "Epoch 43/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0018 - val_loss: 9.9444e-04\n",
      "Epoch 44/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0018 - val_loss: 9.9608e-04\n",
      "Epoch 45/200\n",
      "76/76 [==============================] - 0s 881us/step - loss: 0.0018 - val_loss: 9.9767e-04\n",
      "Epoch 46/200\n",
      "76/76 [==============================] - 0s 856us/step - loss: 0.0018 - val_loss: 9.9923e-04\n",
      "Epoch 47/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 49/200\n",
      "76/76 [==============================] - 0s 871us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 50/200\n",
      "76/76 [==============================] - 0s 873us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 51/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 52/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 53/200\n",
      "76/76 [==============================] - 0s 903us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 54/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 55/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 56/200\n",
      "76/76 [==============================] - 0s 880us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 57/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 58/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 59/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 60/200\n",
      "76/76 [==============================] - 0s 878us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 61/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 62/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 63/200\n",
      "76/76 [==============================] - 0s 855us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 64/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 65/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 66/200\n",
      "76/76 [==============================] - 0s 871us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 67/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 68/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 69/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 70/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 71/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 72/200\n",
      "76/76 [==============================] - 0s 865us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 73/200\n",
      "76/76 [==============================] - 0s 854us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 74/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 75/200\n",
      "76/76 [==============================] - 0s 879us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 76/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 77/200\n",
      "76/76 [==============================] - 0s 883us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "76/76 [==============================] - 0s 882us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "76/76 [==============================] - 0s 876us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 81/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "76/76 [==============================] - 0s 854us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 83/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 84/200\n",
      "76/76 [==============================] - 0s 870us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 85/200\n",
      "76/76 [==============================] - 0s 875us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 86/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 87/200\n",
      "76/76 [==============================] - 0s 859us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 88/200\n",
      "76/76 [==============================] - 0s 855us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 89/200\n",
      "76/76 [==============================] - 0s 854us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 90/200\n",
      "76/76 [==============================] - 0s 886us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 91/200\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 92/200\n",
      "76/76 [==============================] - 0s 901us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 93/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 94/200\n",
      "76/76 [==============================] - 0s 871us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 95/200\n",
      "76/76 [==============================] - 0s 853us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 96/200\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 97/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 98/200\n",
      "76/76 [==============================] - 0s 879us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 99/200\n",
      "76/76 [==============================] - 0s 875us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 100/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 101/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 102/200\n",
      "76/76 [==============================] - 0s 856us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 103/200\n",
      "76/76 [==============================] - 0s 884us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 104/200\n",
      "76/76 [==============================] - 0s 878us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 105/200\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 106/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 107/200\n",
      "76/76 [==============================] - 0s 862us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 108/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 109/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 110/200\n",
      "76/76 [==============================] - 0s 858us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 111/200\n",
      "76/76 [==============================] - 0s 874us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 112/200\n",
      "76/76 [==============================] - 0s 891us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 113/200\n",
      "76/76 [==============================] - 0s 854us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 114/200\n",
      "76/76 [==============================] - 0s 854us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 115/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 116/200\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 117/200\n",
      "76/76 [==============================] - 0s 858us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 118/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 119/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 120/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 121/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 122/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 123/200\n",
      "76/76 [==============================] - 0s 870us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 124/200\n",
      "76/76 [==============================] - 0s 879us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 125/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 126/200\n",
      "76/76 [==============================] - 0s 873us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 127/200\n",
      "76/76 [==============================] - 0s 855us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 128/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 129/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 130/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 131/200\n",
      "76/76 [==============================] - 0s 884us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 132/200\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 133/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 134/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 135/200\n",
      "76/76 [==============================] - 0s 859us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 136/200\n",
      "76/76 [==============================] - 0s 876us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 137/200\n",
      "76/76 [==============================] - 0s 851us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 138/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 139/200\n",
      "76/76 [==============================] - 0s 860us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 140/200\n",
      "76/76 [==============================] - 0s 856us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 141/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 142/200\n",
      "76/76 [==============================] - 0s 852us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 143/200\n",
      "76/76 [==============================] - 0s 896us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 144/200\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 145/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 146/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 147/200\n",
      "76/76 [==============================] - 0s 863us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 148/200\n",
      "76/76 [==============================] - 0s 878us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 149/200\n",
      "76/76 [==============================] - 0s 850us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 150/200\n",
      "76/76 [==============================] - 0s 883us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 151/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 152/200\n",
      "76/76 [==============================] - 0s 887us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 153/200\n",
      "76/76 [==============================] - 0s 882us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 154/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 155/200\n",
      "76/76 [==============================] - 0s 865us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 156/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 157/200\n",
      "76/76 [==============================] - 0s 886us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 158/200\n",
      "76/76 [==============================] - 0s 862us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 159/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0016 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "76/76 [==============================] - 0s 875us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 161/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 162/200\n",
      "76/76 [==============================] - 0s 878us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 163/200\n",
      "76/76 [==============================] - 0s 858us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 164/200\n",
      "76/76 [==============================] - 0s 871us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 165/200\n",
      "76/76 [==============================] - 0s 877us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 166/200\n",
      "76/76 [==============================] - 0s 873us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 167/200\n",
      "76/76 [==============================] - 0s 852us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 168/200\n",
      "76/76 [==============================] - 0s 885us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 169/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 170/200\n",
      "76/76 [==============================] - 0s 883us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 171/200\n",
      "76/76 [==============================] - 0s 854us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 172/200\n",
      "76/76 [==============================] - 0s 862us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 173/200\n",
      "76/76 [==============================] - 0s 885us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 174/200\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 175/200\n",
      "76/76 [==============================] - 0s 881us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 176/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 177/200\n",
      "76/76 [==============================] - 0s 887us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 178/200\n",
      "76/76 [==============================] - 0s 861us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 179/200\n",
      "76/76 [==============================] - 0s 845us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 180/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 181/200\n",
      "76/76 [==============================] - 0s 869us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 182/200\n",
      "76/76 [==============================] - 0s 857us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 183/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 184/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 185/200\n",
      "76/76 [==============================] - 0s 878us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "76/76 [==============================] - 0s 875us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 187/200\n",
      "76/76 [==============================] - 0s 862us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 188/200\n",
      "76/76 [==============================] - 0s 876us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 189/200\n",
      "76/76 [==============================] - 0s 867us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 190/200\n",
      "76/76 [==============================] - 0s 887us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 191/200\n",
      "76/76 [==============================] - 0s 848us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 192/200\n",
      "76/76 [==============================] - 0s 868us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 193/200\n",
      "76/76 [==============================] - 0s 843us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 194/200\n",
      "76/76 [==============================] - 0s 880us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 195/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 196/200\n",
      "76/76 [==============================] - 0s 862us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 197/200\n",
      "76/76 [==============================] - 0s 866us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 198/200\n",
      "76/76 [==============================] - 0s 889us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 199/200\n",
      "76/76 [==============================] - 0s 853us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 200/200\n",
      "76/76 [==============================] - 0s 872us/step - loss: 0.0016 - val_loss: 0.0013\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(12, activation='sigmoid'))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "tf.random.set_seed(12345)\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "#learning rate 0.001\n",
    "\n",
    "history=model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1,shuffle=False, validation_split=0.2)\n",
    "\n",
    "hist = pd.DataFrame(history.history)#beleÅ¾i obuku po epohama\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [Bromacil]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b1af27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007801266037859023"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history=model.evaluate(X_test, y_test, batch_size=1, verbose=0)\n",
    "history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f0dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.5085385 ,  0.01454626, -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.5085385 , -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.27640918, -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.5085385 , -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.5085385 , -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.43599808, -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.01526371, -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525,  0.8823414 ,\n",
       "        -0.16034453, -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.5085385 , -0.2647419 , -0.12565617],\n",
       "       [-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "        -0.5085385 , -0.2647419 , -0.12565617]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96e075ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3abf8673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0., 10.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[73,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09dfa67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01578055],\n",
       "       [0.01791451],\n",
       "       [0.01898957],\n",
       "       [0.01791451],\n",
       "       [0.01791451],\n",
       "       [0.01827471],\n",
       "       [0.01998229],\n",
       "       [0.01028606],\n",
       "       [0.01791451],\n",
       "       [0.01791451]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f79b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0298303, 0.0569165, 0.0302266, 0.0231236, 0.       , 0.       ,\n",
       "       0.0294399, 0.0681038, 0.       , 0.0569165], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b376a920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 7.8013e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0007801264291629195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=model.evaluate(X_test,y_test)\n",
    "\n",
    "y_predict #ukupna greÅ¡ka(MSE)za ceo test skup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e7c439a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.164577  , -0.12847771, -0.1554926 , -0.19873525, -0.10259783,\n",
       "       -0.5085385 , -0.2647419 , -0.12565617], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a948528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007801266037859023"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0b13a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0298303, 0.0569165, 0.0302266, 0.0231236, 0.       , 0.       ,\n",
       "       0.0294399, 0.0681038, 0.       , 0.0569165], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d530893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict output on test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d3393e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02914367\n",
      "R2 Score: -0.3818293930852208\n",
      "MSE: 0.00078012724\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "mae=mean_absolute_error (y_test, y_pred)\n",
    "mae = np.mean(np.abs(y_test - y_predict))\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# assume model and test set data are already defined\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score:\", r2)\n",
    "# calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print the result\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a23e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
